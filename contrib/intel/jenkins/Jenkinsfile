import groovy.transform.Field

properties([disableConcurrentBuilds(abortPrevious: true)])
@Field def DO_RUN=true
@Field def RELEASE=false
@Field def weekly=false
@Field def CTARGET="main"

def checkout_upstream() {
  def loc = "${env.WORKSPACE}/upstream/libfabric"
  sh """
    if [[ ! -d ${env.WORKSPACE}/upstream ]]; then
      mkdir -p ${loc}
    else
      rm -rf ${env.WORKSPACE}/upstream && mkdir -p ${loc}
    fi

    git clone --branch ${CTARGET} ${env.UPSTREAM} ${loc}
  """
}

def checkout_ci_resources() {
  sh """
    if [[ ! -d ${env.WORKSPACE}/upstream ]]; then
      mkdir ${env.WORKSPACE}/ci_resources
    else
      rm -rf ${env.WORKSPACE}/ci_resources && mkdir ${env.WORKSPACE}/ci_resources
    fi

    git clone ${env.CI_RESOURCES} ${env.WORKSPACE}/ci_resources

  """
}

def checkout_ci() {
  sh """
   if [[ ! -d ${env.WORKSPACE}/ci ]]; then
      mkdir ${env.WORKSPACE}/ci
    else
      rm -rf ${env.WORKSPACE}/ci && mkdir ${env.WORKSPACE}/ci
    fi

    git clone --recurse-submodules ${env.CI} ${env.WORKSPACE}/ci
  """
}

def checkout_external_resources() {
  checkout_ci_resources()
  checkout_upstream()
  checkout_ci()
}

def initialize() {
  checkout_tar("source")
  dir (CUSTOM_WORKSPACE) {
    checkout_external_resources()
    sh "mkdir -p ${CUSTOM_WORKSPACE}/log_dir"
    sh "${CI_LOCATION}/bootstrap.sh"
  }
}

def build_ci(config_name) {
  sh """${CI_LOCATION}/venv/bin/python run.py \
        --output=${env.CUSTOM_WORKSPACE}/pre-build \
        --job=${config_name}
     """
}

def run_ci(stage_name, config_name) {
  sh """${CI_LOCATION}/venv/bin/python run.py \
        --output=${env.LOG_DIR}/${stage_name} \
        --job=${config_name}
     """
}

def run_red(config_name) {
  sh """PATH=${CI_LOCATION}/venv/bin/:${env.PATH} red \
        --output ${CUSTOM_WORKSPACE} \
        --config "${CI_LOCATION}/red_configs/${config_name}.json" \
        -v 2
     """
}

def gather_logs(cluster, key, dest, source) {
  def address = "${env.USER}@${cluster}"
  try {
    sh "scp -r -i ${key} ${address}:${source}/* ${dest}/"
  } catch (Exception e) {
    echo "Caught exception ${e} when transfering files from ${cluster}"
  }
}

def CI_summarize(verbose=false) {
  def options = ""
  if (verbose) {
    options = "${options} -v"
  }

  if (weekly || RELEASE) {
    options = "${options} --send-mail"
  }

  sh """source ${CI_LOCATION}/venv/bin/activate;\
        python ${CI_LOCATION}/summarize.py \
        --log_directory=${env.LOG_DIR} \
        ${options}
     """
}

def summarize(item, verbose=false, release=false, send_mail=false) {
  def cmd = "${RUN_LOCATION}/summary.py --summary_item=all"
  if (verbose) {
    cmd = "${cmd} -v "
  }
  if (release) {
    cmd = "${cmd} --release "
  }
  if (send_mail.toBoolean()) {
    cmd = "${cmd} --send_mail "
  }

  sh "python3.9 ${cmd}"
}

def checkout_tar(name) {
  weekly = env.WEEKLY != null ? env.WEEKLY.toBoolean() : false
  def weekly_target = env.WEEKLY_TARGET != null ? env.WEEKLY_TARGET : "main"
  def change_target = env.CHANGE_TARGET != null ? env.CHANGE_TARGET : "main"
  CTARGET = weekly ? weekly_target : change_target
  dir ("${env.CUSTOM_WORKSPACE}/${name}/libfabric") {
    checkout scm
    sh """
      git remote add upstream ${env.UPSTREAM}
      git pull --rebase upstream ${CTARGET}
    """
  }
  dir ("${env.CUSTOM_WORKSPACE}/${name}/") {
    sh "tar -cvf libfabric.tar.gz libfabric/*"
  }
}

def git_diffs() {
  dir ("${CUSTOM_WORKSPACE}/source/libfabric") {
    sh "git diff --name-only HEAD..upstream/${CTARGET} > ./commit_id"
    sh "git diff upstream/${CTARGET}:Makefile.am Makefile.am > ./Makefile.am.diff"
    sh "git diff upstream/${CTARGET}:configure.ac configure.ac > ./configure.ac.diff"
    sh "cat configure.ac | grep AC_INIT | cut -d ' ' -f 2 | cut -d '[' -f 2 | cut -d ']' -f 1 > ./release_num.txt"
  }
}

def release() {
  def file = "${CUSTOM_WORKSPACE}/source/libfabric/commit_id"
  if (!fileExists(file)) {
    echo "file ${file} does not exist"
    echo "CI Run has not rebased with ofiwg/libfabric. Please Rebase."
    return false
  }

  def changes = readFile file
  def changeStrings = new ArrayList<String>()

  for (line in changes.readLines()) {
    changeStrings.add(line)
  }

  if ((changeStrings.toArray().any { it =~ /(Makefile\.am)\b/ }) ||
      (changeStrings.toArray().any { it =~ /(configure\.ac)\b/ })) {
        echo "This is probably a release"
        return true
  }

  return false
}

def skip() {
  def file = "${CUSTOM_WORKSPACE}/source/libfabric/commit_id"
  if (!fileExists(file))
    error("CI Run has not rebased with ofiwg/libfabric. Please Rebase.")

  def changes = readFile file
  def changeStrings = new ArrayList<String>()

  for (line in changes.readLines()) {
    changeStrings.add(line)
  }

  echo "Changeset is: ${changeStrings.toArray()}"
  if (changeStrings.toArray().every { it =~ /(?:fabtests\/pytests|man|prov\/efa|prov\/opx|prov\/cxi|prov\/lpp|contrib\/aws|.github).*$/ }) {
    echo "DONT RUN!"
    return true
  }

  if (changeStrings.isEmpty()) {
    echo "DONT RUN!"
    return true
  }

  return false
}

pipeline {
  agent {
    node {
      label 'cbj-main'
      customWorkspace "workspace/${JOB_NAME}/${env.BUILD_NUMBER}"
    }
  }
  options {
      timestamps()
      timeout(activity: true, time: 6, unit: 'HOURS')
      skipDefaultCheckout()
  }
  environment {
      JOB_CADENCE = 'PR'
      CUSTOM_WORKSPACE="${CB_HOME}/workspace/${JOB_NAME}/${env.BUILD_NUMBER}"
      SLURM_JOB_NAME="${env.JOB_NAME}_${env.BUILD_NUMBER}"
      RUN_LOCATION="${env.CUSTOM_WORKSPACE}/ci_resources/legacy_pipeline_scripts/"
      CI_LOCATION="${env.CUSTOM_WORKSPACE}/ci"
      LOG_DIR = "${env.CUSTOM_WORKSPACE}/log_dir"
      TARGET="main"
  }
  stages {
    stage ('init') {
      parallel {
        stage ('main') {
          steps {
            script {
              initialize()
            }
          }
        }
        stage ('level-zero') {
          agent { node { label 'level-zero' } }
          options { skipDefaultCheckout() }
          steps {
            script {
              initialize()
            }
          }
        }
        stage ('daos') {
          agent { node { label 'daos_head' } }
          options { skipDefaultCheckout() }
          steps {
            script {
              initialize()
            }
          }
        }
      }
    }
    stage ('opt_out') {
      steps {
        script {
          git_diffs()
          RELEASE = release()
          DO_RUN = skip() && !weekly ? false : true
        }
      }
    }
    stage('auth_check') {
      when { equals expected: true, actual: DO_RUN }
      steps {
        script {
          sh """source ${CI_LOCATION}/venv/bin/activate;\
                python ${CI_LOCATION}/authorize.py \
                --author=${env.CHANGE_AUTHOR}
          """
        }
      }
    }
    stage ('health_check') {
      when { equals expected: true, actual: DO_RUN }
      steps {
        script {
          dir (CI_LOCATION) {
            sh "./temperature.sh"
          }
        }
      }
    }
    stage ('build_daos') {
      agent {
        node {
          label 'daos_head'
          customWorkspace CUSTOM_WORKSPACE
        }
      }
      options { skipDefaultCheckout() }
      steps {
        script {
          dir (CI_LOCATION) {
            build_ci("pr_build_daos.json")
          }
        }
      }
    }
    stage ('run') {
      when { equals expected: true, actual: DO_RUN }
      parallel {
        stage ('main') {
          steps {
            script {
              withEnv(["TARGET=CTARGET"]) {
                dir (CI_LOCATION) {
                  run_red("${env.MAIN_CONFIG}")
                }
              }
            }
          }
        }
        stage ('level-zero') {
          agent { node { label 'level-zero' } }
          options { skipDefaultCheckout() }
          steps {
            script {
              dir (CI_LOCATION) {
                run_red("${env.LEVEL_ZERO_CONFIG}")
              }
            }
          }
        }
        stage('daos_tcp') {
          agent { node { label 'daos_tcp' } }
          options { skipDefaultCheckout() }
          steps {
            script {
              dir (RUN_LOCATION) {
                sh """python3.9 runtests.py \
                  --prov='tcp' \
                  --util='rxm' \
                  --test=daos \
                  --build_hw=daos \
                  --log_file=${env.LOG_DIR}/daos_tcp-rxm_reg
                """
              }
            }
          }
        }
        stage('daos_verbs') {
          agent { node { label 'daos_verbs' } }
          options { skipDefaultCheckout() }
          steps {
            script {
              dir (RUN_LOCATION) {
                sh """python3.9 runtests.py \
                  --prov='verbs' \
                  --util='rxm' \
                  --test=daos \
                  --build_hw=daos \
                  --log_file=${env.LOG_DIR}/daos_verbs-rxm_reg
                """
              }
            }
          }
        }
      }
    }
    stage ('Summary') {
      when { equals expected: true, actual: DO_RUN }
      steps {
        script {
          gather_logs("${env.DAOS_ADDR}", "${env.DAOS_KEY}", "${env.LOG_DIR}",
                      "${env.LOG_DIR}")
          gather_logs("${env.LZE_ADDR}", "${env.LZE_KEY}", "${env.LOG_DIR}",
                      "${env.LOG_DIR}")

          CI_summarize(verbose=false)
          summarize("all", verbose=false, release=RELEASE,
                    send_mail=env.WEEKLY.toBoolean())
        }
      }
    }
  }

  post {
    always {
      script {
        if (DO_RUN) {
          CI_summarize(verbose=true)
          CI_summarize()
          summarize("all", verbose=true)
          summarize("all")
        }
      }
      node ('daos_head') {
        dir("${env.WORKSPACE}") { deleteDir() }
        dir("${env.WORKSPACE}@tmp") { deleteDir() }
      }
      node ('level-zero') {
        dir("${env.WORKSPACE}") { deleteDir() }
        dir("${env.WORKSPACE}@tmp") { deleteDir() }
      }
      dir("${env.WORKSPACE}") { deleteDir() }
      dir("${env.WORKSPACE}@tmp") { deleteDir() }
    }
  }
}
